{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple implementation of the BM25 algorithm in python\n",
    "\n",
    "* https://www.elastic.co/blog/practical-bm25-part-2-the-bm25-algorithm-and-its-variables/\n",
    "* https://cs.uwaterloo.ca/~jimmylin/publications/Kamphuis_etal_ECIR2020_preprint.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install bm25s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/corpus.csv\")\n",
    "documents = df[\"text\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b37d2744870a4895afa8a589eeb755b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Split strings:   0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e920b9280c9f47bb8b1aa614d37a16ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BM25S Count Tokens:   0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c219f5b51c1649c59f1be07aa0025051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BM25S Compute Scores:   0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import bm25s\n",
    "corpus_tokens = bm25s.tokenize(documents, stopwords=\"en\")\n",
    "retriever = bm25s.BM25(method=\"lucene\")\n",
    "retriever.index(corpus_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d7df50a8bf24856aed41319ede32da6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Split strings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized(ids=[[0, 1, 2]], vocab={'amore': 0, 'classico': 1, '75': 2})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a5b85a225064d869220a95d4c7399e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BM25S Retrieve:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1 (score: 5.69): Amaretto Di Amore Classico\n",
      "Rank 2 (score: 3.53): Bell'Amore Peach\n",
      "Rank 3 (score: 3.20): Di Amore Raspberry 33\n",
      "Rank 4 (score: 3.20): Di Amore Amaretto 42\n",
      "Rank 5 (score: 3.20): Primo Amore Moscato Puglia\n",
      "Rank 6 (score: 3.20): Di Amore Amaretto 42\n",
      "Rank 7 (score: 3.20): Di Amore Amaretto 42\n",
      "Rank 8 (score: 3.20): Bell'Amore Peach (Sc)\n",
      "Rank 9 (score: 3.20): Di Amore Sambuca 84\n",
      "Rank 10 (score: 3.20): Di Amore Amaretto 42\n"
     ]
    }
   ],
   "source": [
    "query = \"amore classico 1.75\"\n",
    "query_tokens = bm25s.tokenize(query)\n",
    "print(query_tokens)\n",
    "results, scores = retriever.retrieve(query_tokens, corpus=documents, k=10)\n",
    "\n",
    "for i in range(results.shape[1]):\n",
    "    doc, score = results[0, i], scores[0, i]\n",
    "    print(f\"Rank {i+1} (score: {score:.2f}): {doc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['orange', 'amaretto']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "TOKEN_PATTERN = r\"(?u)\\b\\w\\w+\\b\"\n",
    "STOPWORDS = (\n",
    "    \"a\",\n",
    "    \"an\",\n",
    "    \"and\",\n",
    "    \"are\",\n",
    "    \"as\",\n",
    "    \"at\",\n",
    "    \"be\",\n",
    "    \"but\",\n",
    "    \"by\",\n",
    "    \"for\",\n",
    "    \"if\",\n",
    "    \"in\",\n",
    "    \"into\",\n",
    "    \"is\",\n",
    "    \"it\",\n",
    "    \"no\",\n",
    "    \"not\",\n",
    "    \"of\",\n",
    "    \"on\",\n",
    "    \"or\",\n",
    "    \"such\",\n",
    "    \"that\",\n",
    "    \"the\",\n",
    "    \"their\",\n",
    "    \"then\",\n",
    "    \"there\",\n",
    "    \"these\",\n",
    "    \"they\",\n",
    "    \"this\",\n",
    "    \"to\",\n",
    "    \"was\",\n",
    "    \"will\",\n",
    "    \"with\",\n",
    ")\n",
    "\n",
    "def tokenize(text: str) -> list[str]:\n",
    "\n",
    "    split_fn = re.compile(TOKEN_PATTERN).findall\n",
    "\n",
    "    words = split_fn(text)\n",
    "    words = [word.lower().strip() for word in words]\n",
    "    words = [word for word in words if word not in STOPWORDS]\n",
    "    return words\n",
    "\n",
    "tokenize(\"Orange Amaretto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 5.5728, 10204, 10204, 165624)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# f(qi) - document_freq is the number of documents which contain the token term\n",
    "document_freq = defaultdict(int)\n",
    "# f(dj, qi) - term_freq is the number of times the token term appears in document dj\n",
    "term_freq = defaultdict(int)\n",
    "\n",
    "vocab = []\n",
    "doc_lengths = []\n",
    "\n",
    "for doc_id, text in enumerate(documents):\n",
    "\n",
    "    tokens = tokenize(text)\n",
    "    doc_lengths.append(len(tokens))\n",
    "    vocab.extend(tokens)\n",
    "\n",
    "    for token in set(tokens):\n",
    "        document_freq[token] += 1\n",
    "\n",
    "    for token in tokens:\n",
    "        term_freq[(doc_id, token)] += 1\n",
    "\n",
    "vocab = sorted(set(vocab))\n",
    "\n",
    "doc_count = len(documents)\n",
    "mean_doc_length = sum(doc_lengths) / doc_count\n",
    "\n",
    "doc_count, mean_doc_length, len(vocab), len(document_freq), len(term_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 8.168636465892812)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def score_idf(token: str) -> float:\n",
    "    fq = document_freq[token]\n",
    "    inner = (doc_count - fq + 0.5) / (fq + 0.5)\n",
    "    if inner < 1:\n",
    "        inner = 1\n",
    "    return math.log(inner)\n",
    "\n",
    "\n",
    "def score_tf(doc_id: int, token: str, k1 = 1.5, b = 0.75) -> float:\n",
    "    doc_length = doc_lengths[doc_id]\n",
    "    f = term_freq[(doc_id, token)]\n",
    "    return f / (f + k1 * (1 - b + b * doc_length / mean_doc_length))\n",
    "\n",
    "\n",
    "token = vocab[0]\n",
    "score_tf(0, token), score_idf(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def score_query(token: str) -> np.ndarray:\n",
    "    document_scores = []\n",
    "    for doc_id in range(doc_count):\n",
    "        score = score_idf(token) * score_tf(doc_id, token)\n",
    "        document_scores.append(score)\n",
    "    return np.array(document_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1 (score: 5.68): Amaretto Di Amore Classico\n",
      "Rank 2 (score: 3.53): Bell'Amore Peach\n",
      "Rank 3 (score: 3.20): Di Amore Limoncello 53\n",
      "Rank 4 (score: 3.20): Primo Amore Moscato Puglia\n",
      "Rank 5 (score: 3.20): Di Amore Sambuca 84\n",
      "Rank 6 (score: 3.20): Di Amore Sambuca 84\n",
      "Rank 7 (score: 3.20): Di Amore Sambuca 84\n",
      "Rank 8 (score: 3.20): Di Amore Sambuca 84\n",
      "Rank 9 (score: 3.20): Di Amore Sambuca 84\n",
      "Rank 10 (score: 3.20): Di Amore Raspberry 33\n"
     ]
    }
   ],
   "source": [
    "query = \"amore classico\"\n",
    "\n",
    "scores = np.zeros([doc_count])\n",
    "for token in tokenize(query):\n",
    "    scores += np.array(score_query(token))\n",
    "\n",
    "top_k = 10\n",
    "top_k_docs = np.argsort(scores)[::-1][:top_k]\n",
    "top_k_scores = scores[top_k_docs]\n",
    "\n",
    "for i, (doc_id, score) in enumerate(zip(top_k_docs, top_k_scores)):\n",
    "    print(f\"Rank {i+1} (score: {score:.2f}): {documents[doc_id]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "860840f527634546b449f21260897cd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Split strings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14e30a4ea42942fd987acfd3fda93ed1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BM25S Retrieve:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1 (score: 5.69): Amaretto Di Amore Classico\n",
      "Rank 2 (score: 3.53): Bell'Amore Peach\n",
      "Rank 3 (score: 3.20): Terra Valentine Amore 14\n",
      "Rank 4 (score: 3.20): Di Amore Sambuca 84\n",
      "Rank 5 (score: 3.20): Di Amore Amaretto 42\n",
      "Rank 6 (score: 3.20): Di Amore Sambuca 84\n",
      "Rank 7 (score: 3.20): Di Amore Amaretto 42\n",
      "Rank 8 (score: 3.20): Di Amore Sambuca 84\n",
      "Rank 9 (score: 3.20): Di Amore Sambuca 84\n",
      "Rank 10 (score: 3.20): Di Amore Limoncello 53\n"
     ]
    }
   ],
   "source": [
    "query_tokens = bm25s.tokenize(query)\n",
    "results, scores = retriever.retrieve(query_tokens, corpus=documents, k=10)\n",
    "\n",
    "for i in range(results.shape[1]):\n",
    "    doc, score = results[0, i], scores[0, i]\n",
    "    print(f\"Rank {i+1} (score: {score:.2f}): {doc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
